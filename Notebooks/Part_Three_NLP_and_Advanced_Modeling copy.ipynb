{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d0a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "from scipy.stats import f_oneway\n",
    "from scipy import stats\n",
    "import random\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa447ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b929f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>company_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>med_salary</th>\n",
       "      <th>pay_period</th>\n",
       "      <th>formatted_work_type</th>\n",
       "      <th>location</th>\n",
       "      <th>applies</th>\n",
       "      <th>original_listed_time</th>\n",
       "      <th>remote_allowed</th>\n",
       "      <th>views</th>\n",
       "      <th>application_type</th>\n",
       "      <th>expiry</th>\n",
       "      <th>formatted_experience_level</th>\n",
       "      <th>listed_time</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>reposted</th>\n",
       "      <th>skills_present</th>\n",
       "      <th>application_portal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3757940104</td>\n",
       "      <td>553718.0</td>\n",
       "      <td>Hearing Care Provider</td>\n",
       "      <td>Overview\\n\\nHearingLife is a national hearing ...</td>\n",
       "      <td>5250.00</td>\n",
       "      <td>MONTHLY</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Little River, SC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-11-04 05:26:40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>OffsiteApply</td>\n",
       "      <td>2023-12-04 03:53:20</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2023-11-04 05:26:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3757940025</td>\n",
       "      <td>2192142.0</td>\n",
       "      <td>Shipping &amp; Receiving Associate 2nd shift (Beav...</td>\n",
       "      <td>Metalcraft of Mayville\\nMetalcraft of Mayville...</td>\n",
       "      <td>73028.00</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Beaver Dam, WI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-11-04 02:40:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>OffsiteApply</td>\n",
       "      <td>2023-12-04 03:53:20</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>2023-11-04 02:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3757938019</td>\n",
       "      <td>474443.0</td>\n",
       "      <td>Manager, Engineering</td>\n",
       "      <td>\\nThe TSUBAKI name is synonymous with excellen...</td>\n",
       "      <td>73028.00</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Bessemer, AL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-11-04 02:40:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>OffsiteApply</td>\n",
       "      <td>2023-12-04 03:53:20</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>2023-11-04 02:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3757938018</td>\n",
       "      <td>18213359.0</td>\n",
       "      <td>Cook</td>\n",
       "      <td>descriptionTitle\\n\\n Looking for a great oppor...</td>\n",
       "      <td>22.27</td>\n",
       "      <td>HOURLY</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Aliso Viejo, CA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-11-04 02:40:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OffsiteApply</td>\n",
       "      <td>2023-12-04 03:53:20</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>2023-11-04 02:40:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3757937095</td>\n",
       "      <td>437225.0</td>\n",
       "      <td>Principal Cloud Security Architect (Remote)</td>\n",
       "      <td>Job Summary\\nAt iHerb, we are on a mission to ...</td>\n",
       "      <td>240895.00</td>\n",
       "      <td>YEARLY</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>United States</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2023-11-02 20:06:40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>OffsiteApply</td>\n",
       "      <td>2023-12-04 03:53:20</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>2023-11-04 05:26:40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_id  company_id                                              title  \\\n",
       "0  3757940104    553718.0                              Hearing Care Provider   \n",
       "1  3757940025   2192142.0  Shipping & Receiving Associate 2nd shift (Beav...   \n",
       "2  3757938019    474443.0                               Manager, Engineering   \n",
       "3  3757938018  18213359.0                                               Cook   \n",
       "4  3757937095    437225.0        Principal Cloud Security Architect (Remote)   \n",
       "\n",
       "                                         description  med_salary  \\\n",
       "0  Overview\\n\\nHearingLife is a national hearing ...     5250.00   \n",
       "1  Metalcraft of Mayville\\nMetalcraft of Mayville...    73028.00   \n",
       "2  \\nThe TSUBAKI name is synonymous with excellen...    73028.00   \n",
       "3  descriptionTitle\\n\\n Looking for a great oppor...       22.27   \n",
       "4  Job Summary\\nAt iHerb, we are on a mission to ...   240895.00   \n",
       "\n",
       "      pay_period formatted_work_type          location  applies  \\\n",
       "0        MONTHLY           Full-time  Little River, SC      5.0   \n",
       "1  Not Specified           Full-time    Beaver Dam, WI      5.0   \n",
       "2  Not Specified           Full-time      Bessemer, AL      5.0   \n",
       "3         HOURLY           Full-time   Aliso Viejo, CA      5.0   \n",
       "4         YEARLY           Full-time     United States      5.0   \n",
       "\n",
       "  original_listed_time  remote_allowed  views application_type  \\\n",
       "0  2023-11-04 05:26:40             0.0    9.0     OffsiteApply   \n",
       "1  2023-11-04 02:40:00             0.0   16.0     OffsiteApply   \n",
       "2  2023-11-04 02:40:00             0.0   16.0     OffsiteApply   \n",
       "3  2023-11-04 02:40:00             0.0    1.0     OffsiteApply   \n",
       "4  2023-11-02 20:06:40             1.0   16.0     OffsiteApply   \n",
       "\n",
       "                expiry formatted_experience_level          listed_time  \\\n",
       "0  2023-12-04 03:53:20                Entry level  2023-11-04 05:26:40   \n",
       "1  2023-12-04 03:53:20              Not Specified  2023-11-04 02:40:00   \n",
       "2  2023-12-04 03:53:20              Not Specified  2023-11-04 02:40:00   \n",
       "3  2023-12-04 03:53:20                Entry level  2023-11-04 02:40:00   \n",
       "4  2023-12-04 03:53:20           Mid-Senior level  2023-11-04 05:26:40   \n",
       "\n",
       "   sponsored  reposted  skills_present  application_portal  \n",
       "0          0         0               0                   1  \n",
       "1          0         0               0                   1  \n",
       "2          0         0               1                   1  \n",
       "3          0         0               0                   1  \n",
       "4          0         1               0                   1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data from previous notebook\n",
    "df = pd.read_csv('../Data/clean_linkedin_job_posting.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c35f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3dea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e2cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d741cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes([\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes([\"float\", \"int\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e50a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['application_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afefe871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['application_method'] = df['application_type'].map({'OffsiteApply': 0, 'ComplexOnsiteApply': 1, 'SimpleOnsiteApply': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "df['application_method'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930aa9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='application_type', inplace=True)\n",
    "\n",
    "# Sanity Check\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'is_usa' with binary values\n",
    "def check_usa(location):\n",
    "    if 'United States' in str(location):\n",
    "        return 1\n",
    "    elif ',' in str(location):\n",
    "        return 1  # Assume it's in the USA if there's a comma (likely a city-state pair)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['is_usa'] = df['location'].apply(check_usa)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "df['is_usa'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df['is_usa'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.title('Distribution of Location'.title())\n",
    "plt.xlabel(\"USA vs World\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='location', inplace=True)\n",
    "\n",
    "# Sanity Check\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['original_listed_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198edbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['expiry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceea833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['listed_time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb309d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp columns to datetime format\n",
    "df['original_listed_time'] = pd.to_datetime(df['original_listed_time'])\n",
    "df['expiry'] = pd.to_datetime(df['expiry'])\n",
    "df['listed_time'] = pd.to_datetime(df['listed_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bfedc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month, day, hour, minute, and second into separate columns\n",
    "df['original_listed_year'] = df['original_listed_time'].dt.year\n",
    "df['original_listed_month'] = df['original_listed_time'].dt.month\n",
    "df['original_listed_day'] = df['original_listed_time'].dt.day\n",
    "df['original_listed_hour'] = df['original_listed_time'].dt.hour\n",
    "df['original_listed_minute'] = df['original_listed_time'].dt.minute\n",
    "df['original_listed_second'] = df['original_listed_time'].dt.second\n",
    "\n",
    "df['expiry_year'] = df['expiry'].dt.year\n",
    "df['expiry_month'] = df['expiry'].dt.month\n",
    "df['expiry_day'] = df['expiry'].dt.day\n",
    "df['expiry_hour'] = df['expiry'].dt.hour\n",
    "df['expiry_minute'] = df['expiry'].dt.minute\n",
    "df['expiry_second'] = df['expiry'].dt.second\n",
    "\n",
    "df['listed_year'] = df['listed_time'].dt.year\n",
    "df['listed_month'] = df['listed_time'].dt.month\n",
    "df['listed_day'] = df['listed_time'].dt.day\n",
    "df['listed_hour'] = df['listed_time'].dt.hour\n",
    "df['listed_minute'] = df['listed_time'].dt.minute\n",
    "df['listed_second'] = df['listed_time'].dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e315f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19eb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original_listed_time, expiry, and listed_time columns\n",
    "df.drop(['original_listed_time', 'expiry', 'listed_time'], axis=1, inplace=True)\n",
    "\n",
    "# Sanity Check\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5eb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables\n",
    "dummy_variables = pd.get_dummies(df[['pay_period', 'formatted_work_type', 'formatted_experience_level']])\n",
    "\n",
    "# Concatenating the dummy variables with the original DataFrame\n",
    "df_dummies = pd.concat([df, dummy_variables], axis=1)\n",
    "\n",
    "# Optionally, you might want to drop the original columns to avoid redundancy\n",
    "df_dummies = df_dummies.drop(['pay_period', 'formatted_work_type', 'formatted_experience_level'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1eacaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8bfdf",
   "metadata": {},
   "source": [
    "## Text Analysis - NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice out target variable and independant variables\n",
    "y = df_dummies['views']\n",
    "X = df_dummies.drop('views', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cf16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 30% test size and 70% train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use .shape to look at size of training data\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a0198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice out title and description train and test reviews\n",
    "title_X_train = X_train['title']\n",
    "desc_X_train = X_train['description']\n",
    "\n",
    "title_X_test = X_test['title']\n",
    "desc_X_test = X_test['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e43e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate CountVectorizer\n",
    "title_bow = CountVectorizer(max_features=500, min_df = 10)\n",
    "desc_bow = CountVectorizer(max_features=500, min_df = 10)\n",
    "\n",
    "# fit the model to training set\n",
    "title_bow.fit(title_X_train)\n",
    "desc_bow.fit(desc_X_train)\n",
    "\n",
    "# transform the training set\n",
    "title_train_transform = title_bow.transform(title_X_train)\n",
    "desc_train_transform = desc_bow.transform(desc_X_train)\n",
    "\n",
    "# transform the test set\n",
    "title_test_transform = title_bow.transform(title_X_test)\n",
    "desc_test_transform = desc_bow.transform(desc_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb95cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39413a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67847b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can sum up the words in an array and store it in DataFrame()\n",
    "word_counts = pd.DataFrame(\n",
    "    {\"counts\": title_train_transform.toarray().sum(axis=0)},\n",
    "    index=title_bow.get_feature_names_out()\n",
    ").sort_values(\"counts\", ascending=False)\n",
    "\n",
    "#head(20) looks at the top 20 words when ascending=False\n",
    "word_counts.head(20).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "\n",
    "plt.title(\"Top 20 most frequently occurring words in Job Titles\".title())\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45) # this rotates the xlabels to make them easier to read\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e04f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can sum up the words in an array and store it in DataFrame()\n",
    "word_counts = pd.DataFrame(\n",
    "    {\"counts\": desc_train_transform.toarray().sum(axis=0)},\n",
    "    index=desc_bow.get_feature_names_out()\n",
    ").sort_values(\"counts\", ascending=False)\n",
    "\n",
    "#head(20) looks at the top 20 words when ascending=False\n",
    "word_counts.head(20).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "\n",
    "plt.title(\"Top 20 most frequently occurring words in Job Descriptions\".title())\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45) # this rotates the xlabels to make them easier to read\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a80fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate CountVectorizer and add stop words\n",
    "title_bow = CountVectorizer(stop_words='english', max_features=500, min_df = 10)\n",
    "desc_bow = CountVectorizer(stop_words='english', max_features=500, min_df = 10)\n",
    "\n",
    "# fit the model to training set\n",
    "title_bow.fit(title_X_train)\n",
    "desc_bow.fit(desc_X_train)\n",
    "\n",
    "# transform the training set\n",
    "title_train_transform = title_bow.transform(title_X_train)\n",
    "desc_train_transform = desc_bow.transform(desc_X_train)\n",
    "\n",
    "# transform the test set\n",
    "title_test_transform = title_bow.transform(title_X_test)\n",
    "desc_test_transform = desc_bow.transform(desc_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af301655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we can sum up the words in an array and store it in DataFrame()\n",
    "word_counts = pd.DataFrame(\n",
    "    {\"counts\": title_train_transform.toarray().sum(axis=0)},\n",
    "    index=title_bow.get_feature_names_out()\n",
    ").sort_values(\"counts\", ascending=False)\n",
    "\n",
    "#head(20) looks at the top 20 words when ascending=False\n",
    "word_counts.head(20).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "\n",
    "plt.title(\"Top 20 most frequently occurring words in Job Titles Without Stop-Words\".title())\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45) # this rotates the xlabels to make them easier to read\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can sum up the words in an array and store it in DataFrame()\n",
    "word_counts = pd.DataFrame(\n",
    "    {\"counts\": desc_train_transform.toarray().sum(axis=0)},\n",
    "    index=desc_bow.get_feature_names_out()\n",
    ").sort_values(\"counts\", ascending=False)\n",
    "\n",
    "#head(20) looks at the top 20 words when ascending=False\n",
    "word_counts.head(20).plot(kind=\"bar\", figsize=(15, 5), legend=False)\n",
    "\n",
    "plt.title(\"Top 20 most frequently occurring words in Job Descriptions without Stop-Words\".title())\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45) # this rotates the xlabels to make them easier to read\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add prefix title_ to the title columns\n",
    "title_col_name = ['title_' + word for word in title_bow.get_feature_names_out()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert title training sparse matrix into dataframes\n",
    "# Source(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sparse.from_spmatrix.html)\n",
    "title_df = pd.DataFrame.sparse.from_spmatrix(title_train_transform, columns = title_col_name).sparse.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(title_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea93242",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07698181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11d75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba6688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8dc645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33cc8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a01c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting indexes\n",
    "#X_train.reset_index(drop=True, inplace=True)\n",
    "#y_train.reset_index(drop=True, inplace=True)\n",
    "#title_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenating DataFrames\n",
    "#new_X_train = pd.concat([X_train, title_df], axis=1) #axis=1 makes sure it adds by column and not row\n",
    "#new_X_train.drop(columns = ['title','description'], inplace=True)\n",
    "#new_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3296c7",
   "metadata": {},
   "source": [
    "The number of rows (23,272) and columns are correct (columns = 500 + 49)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b3634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pos and neg testing sparse matrix into dataframes\n",
    "# Source(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sparse.from_spmatrix.html)\n",
    "#title_test_df = pd.DataFrame.sparse.from_spmatrix(title_test_transform, columns = title_col_name).sparse.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db76dfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting indexes\n",
    "#X_test.reset_index(drop=True, inplace=True)\n",
    "#y_test.reset_index(drop=True, inplace=True)\n",
    "#title_test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenating DataFrames\n",
    "#new_X_test = pd.concat([X_test, title_test_df], axis=1) #axis=1 makes sure it adds by column and not row\n",
    "#new_X_test.drop(columns = ['title','description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = pd.DataFrame()\n",
    "\n",
    "#max_depth_values = [3, 6, 9, 12]\n",
    "\n",
    "# loop through the max depth values\n",
    "#for max_depth in max_depth_values:\n",
    "    #dt_model = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    #dt_model.fit(new_X_train, y_train)\n",
    "\n",
    "    # scoring\n",
    "    #train_score = dt_model.score(new_X_train, y_train)\n",
    "    #test_score = dt_model.score(new_X_test, y_test)\n",
    "\n",
    "    # append results\n",
    "    #new_row = {'Depth': max_depth, 'Train Score': train_score, 'Test Score': test_score}\n",
    "    #scores = pd.concat([scores, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "# best parameter\n",
    "#best_score = scores['Test Score'].max()\n",
    "#print(\"Best test scores given by:\")\n",
    "#print(scores[scores['Test Score'] == best_score], \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c394edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison plot\n",
    "#plt.figure(figsize=(10,5))\n",
    "#plt.plot('Depth', 'Train Score', data=scores)\n",
    "#plt.plot('Depth', 'Test Score', data=scores)\n",
    "#plt.title('Accuracies as Depth Changes')\n",
    "#plt.xlabel('Depth')\n",
    "#plt.xticks(max_depth_values)\n",
    "#plt.ylabel('Accuracy Score')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbd3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22277c1f",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbfa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from scipy.stats import randint,uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb56f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1cbed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cd715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e7cb29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Defining the hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100],\n",
    "    'rf__max_depth': [10, 20],\n",
    "    'rf__min_samples_split': [2, 5],\n",
    "    'rf__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Defining the scoring metric (Root Mean Squared Error in this case)\n",
    "scorer = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "# Creating the GridSearchCV object with verbose parameter\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring=scorer, cv=3, verbose=4)\n",
    "\n",
    "# Fitting the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80478b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the best hyperparameters\n",
    "best_hyperparameters = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b99d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "model = RandomForestRegressor(n_estimators=50,\n",
    "                    max_depth=10,\n",
    "                    min_samples_split=2,\n",
    "                    min_samples_leaf=1)\n",
    "# Training the model on the training data\n",
    "model.fit(new_X_train, y_train)\n",
    "# Making predictions on the testing set\n",
    "y_pred_test = model.predict(new_X_test)\n",
    "# Making predictions on the training set\n",
    "y_pred_train = model.predict(new_X_train)\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_train, y_pred_train)\n",
    "print(f\"R-squared (R^2) value: {r2}\")\n",
    "# Calculating R-squared\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"R-squared (R^2) value: {r2}\")\n",
    "# Calculating MAE for training set\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(f\"Mean Absolute Error (MAE) for TRAIN set: {mae_train}\")\n",
    "# Calculating MAE for test set\n",
    "mae_test =mean_absolute_error(y_test, y_pred_test)\n",
    "print(f\"Mean Absolute Error (MAE) for TEST set: {mae_test}\")\n",
    "# Creating a DataFrame with actual and predicted values for the training set\n",
    "train_results = pd.DataFrame({'Actual': y_train, 'Predicted': y_pred_train})\n",
    "# Creating a DataFrame with actual and predicted values for the test set\n",
    "test_results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae15ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb052ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a493d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3acf13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd3c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fd78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8fc015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d33a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LinkedIn_Capstone",
   "language": "python",
   "name": "linkedin_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
